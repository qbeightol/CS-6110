\documentclass[10pt]{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{mathpartir}
% \usepackage{parskip}
\usepackage{stmaryrd}
\usepackage{enumerate, verbatim}

\pagestyle{fancy}

\lhead{\sf CS 6110 Homework 2}
\rhead{\sf Giang Nguyen (htn26) and Quinn Beightol (qeb2)}


% Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\problem}[1]{\section{\sf #1}}
\newcommand{\translate}[2]{\ensuremath {\llbracket #1 \rrbracket}_{#2}}
\newcommand{\defined}{\triangleq}
\renewcommand{\S}{\textsf{S}}
\newcommand{\K}{\textsf{K}}
\newcommand{\I}{\textsf{I}}
\newcommand{\stepsA}{\rightarrow_a}
\newcommand{\stepsB}{\rightarrow_b}
\newcommand{\steps}{\rightarrow}
\newcommand{\for}[2]{\textsf{for}~#1~\textsf{do}~#2}
\newcommand{\config}[2]{\langle#1,~#2\rangle}
\newcommand{\impSkip}{\textsf{skip}}
\newcommand{\bigStepsA}{\Downarrow_a}
\newcommand{\bigStepsB}{\Downarrow_b}
\newcommand{\bigSteps}{\Downarrow}
\renewcommand{\gets}[2]{#1~\texttt{:=}~#2}
\newcommand{\Rule}[3]{
  [\textsc{#1}]~
  \label{rule:#1}
  \hfill
  \ensuremath{\inferrule{#2}{#3}}
  \hfill
}
\newcommand{\RuleWithCondition}[4]{
  [\textsc{#1}]~
  \label{rule:#1}
  \hfill
  \ensuremath{\inferrule{#2}{#3}}
  (#4)
  \hfill
}

\newtheorem{claim}{Claim}[section]
\newtheorem{lemma}{Lemma}[claim]


\begin{document}
\problem{Observational Equivalence}

\textbf{Lemma 1:}
\begin{enumerate}[(i)]
\item \textbf{Claim: } $\equiv_{obs}$ is an equivalence relation assuming that $\equiv$ is also an equivalence relation.

\begin{enumerate}
\item Consider a term $e$. We will prove that $e \equiv_{obs} e$.

For any context $C$, $C[e] \Downarrow$ if and only if $C[e]$ itself converges. In other words,  $C[e] \Downarrow$ iff  $C[e] \Downarrow$.

Suppose $C[e] \Downarrow v_1$ and $C[e] \Downarrow v_2$ under CBV evaluation. Since CBV is deterministic $v_1$ and $v_2$ must be syntactically equivalent. $\equiv$ is reflexive since it is an equivalence relation, $v_1 \equiv v_2$. Therefore $\equiv_{obs}$ is also reflexive.
\item Suppose $e_1 \equiv_{obs} e_2$ we will prove that $e_2 \equiv_{obs} e_1$.

$e_1 \equiv_{obs} e_2$ so $C[e_1] \Downarrow$ iff $C[e_2] \Downarrow \Rightarrow C[e_2] \Downarrow$ iff $C[e_1] \Downarrow$.

Suppose $C[e_1] \Downarrow v_1$ and $C[e_2] \Downarrow v_2$ under CBV evaluation then $v_1 \equiv v_2$ since $e_1 \equiv_{obs} e_2 \Rightarrow v_2 \equiv v_2$ because $\equiv$ is symmetric.

$\Rightarrow e_2 \equiv_{obs} e_1$. $\equiv_{obs}$ is symmetric.
\item Let $e_1, e_2$ and $e_3$ be $3$ terms such that $e_1 \equiv_{obs} e_2$ and $e_2 \equiv_{obs} e_3$.

For any context $C$, $C[e_1] \Downarrow$ if and only if $C[e_2] \Downarrow$ if and only if $C[e_3] \Downarrow$.

Suppose $C[e_1] \Downarrow v_1, C[e_2] \Downarrow v_2$ and $C[e_3] \Downarrow v_3$ then $v_1 \equiv v_2$ and $v_2 \equiv v_3 \Rightarrow v_1 \equiv v_3$ as $\equiv$ is transitive.

Thus $\equiv_{obs}$ is transitive. $\Box$
\end{enumerate}
\item \textbf{Claim}: $\equiv_{obs}$ refines $\equiv$.

Let $v_1$ and $v_2$ be $2$ values such that $v_1 \equiv_{obs} v_2$. Let $C[.]$ be the context $[.]$ that only has a hole.

$C[v_1] = v_1$ and $C[v_2] = v_2$.

$C[v_1] \equiv C[v_2]$ since   $v_1 \equiv_{obs} v_2 \Rightarrow v_1 \equiv v_2 \Box$.
\item This part is exactly the first condition in the definition of $\equiv_{obs}$.
\item Suppose $\equiv^1$ refines $\equiv^2$ and $e_1 \equiv^1_{obs} e_2$. We will prove that $e_1 \equiv^2_{obs} e_2$.

$e_1 \equiv^1_{obs} e_2$ so for any context $C$, $C[e_1] \Downarrow$ if and only if $C[e_2] \Downarrow$.

If $C$ is a context such that $C[e_1] \Downarrow v_1$ and $C[e_2] \Downarrow v_2$ then $v_1 \equiv^1 v_2 \Rightarrow v_1 \equiv^2 v_2 \Box$.
\end{enumerate}

%TODO
%Fix the indentation
\textbf{Theorem 2}: For CBV and CBN, $\equiv_{\Downarrow}$ is a fixed point of the transformation $\equiv$  $\mapsto$  $\equiv_{obs}$  and is the coarsest such fixed point.

First we will prove that $e_1 \equiv_{\Downarrow} e_2$ if and only if $e_1  (\equiv_{\Downarrow})_{obs} e_2$.

$(\Rightarrow)$ Suppose  $e_1 \equiv_{\Downarrow} e_2$ then by definition for any context $C$, $C[e_1] \Downarrow$ iff $C[e_2] \Downarrow$.

Consider an arbitrary context $C$ such that $C[e_1] \Downarrow v_1$ and $C[e_2] \Downarrow v_2$ under CBV evaluation rules. In fact this entire proof can be used to prove the case for CBN evaluation just by replacing CBV with CBN.

%TODO

$(\Leftarrow)$ This follows directly from (ii) of Lemma 1. $(\equiv_{\Downarrow})_{obs}$ refines $\equiv_{\Downarrow}$.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\problem{Set Operators and Fixed Points}

\textbf{Claim}: Given any set $A$ there is a least fixed point of $\overline R$.\\

\textbf{Proof:} Suppose $\overline R$ is a set operator on some set $N$ then $\overline R : N \rightarrow N$ and $\overline R (N) \subseteq N$.

But $N \subseteq \overline R (N)$ by definition of $\overline{N} \Rightarrow N = \overline{R} (N)$. $N$ is a fixed point.

Let $\overline{A} = \bigcap \{A' | \overline{R} (A') = A' \text{ and } A \subseteq A'\}$. In other words $\overline{A}$ is the intersection of all the fixed point containing $A$. We know that there is at least one such fixed point, i.e. $N$ itself.

First it's easy to see that $\overline{A}$ contains $A$.

For any arbitrary fixed point $A'$ that contains $A$, $\overline{A} \subseteq A'\Rightarrow \overline{R} (\overline{A}) \subseteq \overline R (A') = A'$ by the monotinicity of $\overline R$. Since this is true for any fixed point $A'$ containing $A$,  $\overline{R} (\overline{A}) \subseteq \bigcap \{A' | \overline{R} (A') = A' \text{ and } A \subseteq A'\} = \overline{A}$.

$\overline{A} \subseteq \overline{R} (\overline{A})$ so $\overline{A} = \overline{R} (\overline{A})$ and $\overline{A}$ is also a fixed point containing $A$.

$\overline{A}$ is the least among all such fixed points as if $A'$ is also a fixed point containing $A$, $\overline{A} \subseteq A' \Box$.\\

To get an example of set operator that is monotonic but not increasing, consider a set operator $S$ on the natural numbers $\mathbb{N}$: $S (A)\defined \{n+1 | n \in A\}$.

If $A \subseteq B$ and $x \in S(A) \Rightarrow x-1 \in A \Rightarrow x-1 \in B \Rightarrow x \in S(B) \Rightarrow S(A) \subseteq S(B)$ so $S$ is monotonic.

$S\{0\} = \{1\} \nsupseteq \{0\}$ so obviously $S$ is not increasing.

Let $A = \{0\}$. To see that there is no least fixed point of $S$ that contains $A$ consider any nonempty set $B \subset \mathbb{N}$. There must exist a least element in $B$ (using the normal $\leq$ ordering). Let $x$ be this minimum element then it is easy to see that $x \notin S(B)$ else $x-1 \in B$ which contradicts to the assumption that no element less than $x$ belongs to $B$. So $B$ cannot be a fixed point of $S$. In fact the only fixed point of $S$ is $\varnothing$.

 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\problem{Combinators} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}[(a)]
  \item $\I \defined \S~\K~\K$

  $\S~\K~\K~x \rightarrow \K~x~(\K~x) \rightarrow x$
  \item $ \lambda x y.y \defined \S~\K$

  $\S~\K~x~y \rightarrow \K~x(y~x) \rightarrow x$
  \item $\Omega \defined (\S~ \I~ \I) (\S~ \I~ \I)$

  $\S~ \I~ \I~x \rightarrow \I ~ x ~ (\I ~ x) \rightarrow x~x$
  \item
  \item

  % NOTE: this translation doesn't work. Try translating something with a
  % top-level application (ex: Î©). But it might have some salvageable ideas.

  Use $\translate{e}{V}$ to translate a lambda term $e$ in a context
  where the list of variables $V$ are in scope. The order of variables indicate
  when the variable was introduced. E.g. the variables for translating $e$ in
  $\lambda x. \lambda y. e$ would be $V = x, y$)

  \begin{eqnarray*}
    \translate{x}{x, V}         & \defined & \I                  \\
    \translate{x}{y, V}         & \defined & \K~\translate{x}{V} \\
    \translate{\lambda x. e}{V} & \defined & \translate{e}{V,x}  \\
    \translate{e_1~e_2}{V}      & \defined & \S~\translate{e_1}{V}~\translate{e_2}{V}
  \end{eqnarray*}

  To translate closed $\lambda$-terms, use the empty context (denoted $\cdot$).

\end{enumerate}
\problem{For Loops} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}[(a)]
  \item
  \Rule{LoopEvalA}{
    \config{a}{\sigma} \stepsA a'
  }{
    \config{\for{a}{c}}{\sigma} \steps \config{\for{a'}{c}}{\sigma}
  }

  \RuleWithCondition{LoopEvalBody}{}{
    \config{\for n c}{\sigma} \steps \config{c; \for{n - 1}{c}}{\sigma}
  }{$n > 0$}
  \RuleWithCondition{LoopExit}{}{
    \config{\for n c}{\sigma} \steps \config{\impSkip}{\sigma}
  }{$n \leq 0$}

  \item
  \RuleWithCondition{LoopUnroll}{
    a \bigStepsA n \\
    \forall i \in [1, n].~\config{c}{\sigma_i} \bigSteps \sigma_{i+1}
  }{
    \config{\for a c}{\sigma_1} \bigSteps \sigma_{n+1}
  }{$n > 0$}

  \RuleWithCondition{LoopSkip}{
    a \bigStepsA n
  }{
    \config{\for a c}{\sigma} \bigSteps \sigma
  }{$n \leq 0$}

  \item
  % \underline{Claim:} \\*
  \begin{claim}
    If   $\config{c}{\sigma} \bigSteps \sigma_1$
    and  $\config{c}{\sigma} \bigSteps \sigma_2$
    then $\sigma_1 = \sigma_2$
  \end{claim}

  \begin{proof} By induction on the derivation of $\config{c}{\sigma} \bigSteps
    \sigma_1$ and a case analysis on the last rule used in that derivation.
    We'll also use the following lemmas:

    \begin{lemma} \label{evalA}
      If   $\config{a}{\sigma} \bigStepsA n_1$
      and  $\config{a}{\sigma} \bigStepsA n_2$
      then $n_1 = n_2$.
    \end{lemma}

    \begin{lemma} \label{evalB}
      If   $\config{b}{\sigma} \bigStepsB t_1$
      and  $\config{b}{\sigma} \bigStepsB t_2$
      then $t_1 = t_2$.
    \end{lemma}

    \underline{Skip:} $c = \impSkip$ so the the only applicable evaluation rule
    is $\config{c}{\sigma} \bigSteps \sigma$. Both $\sigma_1$ and $\sigma_2$
    must equal $\sigma$. \\*

    \underline{Assignment:}
    Here, $c = x := a$ and the derivation for $\config{c}{\sigma} \bigSteps
    \sigma_1$ takes the following form:

    $$\inferrule{
      \config{a}{\sigma} \bigStepsA n_1
    }{
      \config{x := a}{\sigma} \bigSteps \sigma[n_1 / x]
    }$$

    Because $c$ is an assignment, the last step in the $\config{c}{\sigma}
    \bigSteps \sigma_1$ derivation must use IMP's evaluation assignment rule:

    $$\inferrule{
      \config{a}{\sigma} \bigStepsA n_2
    }{
      \config{x := a}{\sigma} \bigSteps \sigma[n_2 / x]
    }$$

    Applying \ref{evalA} provides $n_1 = n_2$, which implies $\sigma_1 =
    \sigma_2$. \\*

    \underline{Sequence:}

    $$ c = c_1; c_2 $$

    $ \inferrule{
      \config{c_1}{\sigma}    \bigSteps \sigma_1'\\
      \config{c_2}{\sigma_1'} \bigSteps \sigma_1 \\
    }{
      \config{c_1; c_2}{\sigma} \bigSteps \sigma_1 \\
    }
    \hfill
    \inferrule{
      \config{c_1}{\sigma}    \bigSteps \sigma_2'\\
      \config{c_2}{\sigma_2'} \bigSteps \sigma_2 \\
    }{
      \config{c_1; c_2}{\sigma} \bigSteps \sigma_2 \\
    }
    $ \\*

    Applying the inductive hypothesis yields $\sigma_1' = \sigma_2'$, and
    applying the IH again provides $\sigma_1 = \sigma_2$.


  \end{proof}



\end{enumerate}
\problem{Implementing IMP} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
See our IMP submission.
\problem{Debriefing} %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
DO NOT FORGET THIS TIMEEEEE

\begin{enumerate}[(a)]
  \item
  \item
  \item
  \item
  \item
\end{enumerate}
\end{document}
